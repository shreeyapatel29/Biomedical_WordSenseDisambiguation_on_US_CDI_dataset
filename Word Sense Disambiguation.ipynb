{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import math as m\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from string import punctuation as puncs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#cleaning the dataset\n",
    "df = pd.read_csv('Chronic_Disease_dataset.csv')\n",
    "df = df[['Topic', 'Question']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes                                           110251\n",
       "Cardiovascular Disease                             108803\n",
       "Chronic Obstructive Pulmonary Disease              106860\n",
       "Cancer                                             104580\n",
       "Asthma                                              54884\n",
       "Arthritis                                           54810\n",
       "Overarching Conditions                              54531\n",
       "Nutrition, Physical Activity, and Weight Status     53619\n",
       "Alcohol                                             46998\n",
       "Tobacco                                             41652\n",
       "Older Adults                                        19536\n",
       "Chronic Kidney Disease                              18024\n",
       "Oral Health                                         15075\n",
       "Mental Health                                        9615\n",
       "Immunization                                         6960\n",
       "Reproductive Health                                  5347\n",
       "Disability                                           3392\n",
       "Name: Topic, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing value counts\n",
    "df.Topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Diabetes', 'Cardiovascular Disease', 'Chronic Obstructive Pulmonary Disease', 'Cancer']\n"
     ]
    }
   ],
   "source": [
    "classes = df.Topic.value_counts().head(4).index.tolist()\n",
    "#printing most common classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430494, 2)\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[df['Topic'].isin(classes)]\n",
    "print(df.shape)\n",
    "df.to_csv('dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "train, test = train_test_split(df, test_size=0.5, random_state=42, stratify=df[['Topic']])\n",
    "train.to_csv('train.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)\n",
    "\n",
    "\n",
    "for cls in classes:\n",
    "    out = '. '.join(df[df.Topic==cls][\"Question\"])\n",
    "    with open(cls+\".txt\", \"w\") as text_file:\n",
    "        text_file.write(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "\n",
    "def preprocessing(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    # word tokenization: spliting the snetence into words\n",
    "    words = [w for w in text.split(\" \")]\n",
    "    \n",
    "    # making a set of all stop worked in english using nltk stopwords coupus\n",
    "    stop_words = set(stopwords.words(\"english\")) \n",
    "    \n",
    "    trans = str.maketrans(\"\", \"\", puncs)\n",
    "    words = [w.translate(trans) for w in words]\n",
    "            \n",
    "    # removing stop words \n",
    "    words = [w for w in words if w not in stop_words]\n",
    "            \n",
    "    \n",
    "    # creating a list to get all the words after preprocessing\n",
    "    clean_sent = []\n",
    "    # making a WordNet lemmatizer's object using nltk\n",
    "    lemmatizer = WordNetLemmatizer()  \n",
    "    # creating the object of porter stemmer \n",
    "    ps = PorterStemmer()  \n",
    "    \n",
    "    #stemming and lemmatization\n",
    "    for w in words:\n",
    "        w = ps.stem(w)\n",
    "        w = lemmatizer.lemmatize(w)\n",
    "\n",
    "        clean_sent.append(w)\n",
    "            \n",
    "    return clean_sent\n",
    "\n",
    "### function to calculate term frequency in the doc\n",
    "def termFrequencyInDoc(wordList):\n",
    "#     \"\"\"\n",
    "#     This function should take a list of words as input argument, and output a dictionary of words such that\n",
    "#     each word that appears in the document is key in the dictionary and it's value is term frequency\n",
    "#     \"\"\"\n",
    "    termFrequency_dic={}\n",
    "    for w in wordList:\n",
    "        if w in termFrequency_dic.keys():\n",
    "            termFrequency_dic[w]+=1\n",
    "        else:\n",
    "            termFrequency_dic[w]=1\n",
    "    return termFrequency_dic\n",
    "\n",
    "\n",
    "\n",
    "# termFrequencyInDoc(removePuncs(wordList(txtFile)))\n",
    "def txtfToDictionary(txtFile):\n",
    "    text = open(txtFile, \"r\").read()\n",
    "    return termFrequencyInDoc(preprocessing(text))\n",
    "\n",
    "\n",
    "## function to calculate word Document frequency\n",
    "def wordDocFre(dicList):\n",
    "    vocan = {}\n",
    "    for docDic in dicList:\n",
    "        for keys in docDic.keys():\n",
    "            if keys in vocan.keys():\n",
    "                ## add some code here\n",
    "                vocan[keys]+=1\n",
    "            else:\n",
    "                ## add some code here\n",
    "                vocan[keys]=1\n",
    "    return vocan\n",
    "\n",
    "\n",
    "## construct a function named inverseDocFre() that takes dictionary returned from wordDocFre functions above\n",
    "## and outputs inverse document frequency of each word. You can do it!\n",
    "def invrDocFre(dic,M,Base):\n",
    "    dictidf = {}\n",
    "    for keys in dic.keys():\n",
    "        if(dic[keys]!=0):\n",
    "            dictidf[keys]= math.log((float(M+1)/dic[keys]),Base)\n",
    "        else:\n",
    "            print(keys+\"  \"+str(dic[keys]))\n",
    "    return dictidf\n",
    "\n",
    "\n",
    "\n",
    "### this function will calculate tf-idf for everyword in doc\n",
    "## this is the main function which calls the above functions\n",
    "def tfidf(list_of_doc_dic,idf_dic): \n",
    "    #first input is the list of all disctionaries after Punctuations have been removed\n",
    "    \n",
    "    list_of_tfidf_dic=[] #this contains tfidf dictionaries for each document\n",
    "    for dic in list_of_doc_dic:\n",
    "        tfidf_dic = {}\n",
    "        for keys in dic.keys():\n",
    "            tfidf_dic[keys] = dic[keys] * idf_dic[keys]\n",
    "        list_of_tfidf_dic.append(tfidf_dic)\n",
    "        \n",
    "    return list_of_tfidf_dic\n",
    "\n",
    "\n",
    "def get_synonyms(word):\n",
    "    return [s.name() for synonym in wordnet.synsets(word) for s in synonym.lemmas()]\n",
    "\n",
    "def count_simlilarity(word1, word2):\n",
    "    \n",
    "    try:\n",
    "        word1 = wordnet.synsets(word1)[0].name()\n",
    "        word2 = wordnet.synsets(word2)[0].name()\n",
    "        w1 = wordnet.synset(word1)\n",
    "        w2 = wordnet.synset(word2)\n",
    "        s = w1.wup_similarity(w2)\n",
    "        \n",
    "        if(s>0):\n",
    "            return w1.wup_similarity(w2)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Diabetes', 'Cardiovascular Disease', 'Chronic Obstructive Pulmonary Disease', 'Cancer']\n",
    "\n",
    "dicList = []\n",
    "for cls in classes:\n",
    "    dicList.append(txtfToDictionary(cls+\".txt\"))\n",
    "    \n",
    "WDF_dict = wordDocFre(dicList)\n",
    "IDF_dict = invrDocFre(WDF_dict,len(classes),10)\n",
    "TFIDF_dic_List = tfidf(dicList,IDF_dict)\n",
    "\n",
    "Doc_V = []\n",
    "Vocabulary = np.transpose(np.array(pd.Series(IDF_dict).index))\n",
    "for docdic in TFIDF_dic_List:\n",
    "    Document_V = np.zeros(len(Vocabulary))\n",
    "    for keys in docdic.keys():\n",
    "        Document_V[np.where(Vocabulary == keys)] = docdic[keys]\n",
    "    Doc_V.append(Document_V)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def tfidf_classify(Query):\n",
    "\n",
    "    doc_score_dic = {}\n",
    "    Vocabulary = np.transpose(np.array(pd.Series(IDF_dict).index))\n",
    "    Query_V = np.zeros(len(Vocabulary))\n",
    "\n",
    "    words_q = preprocessing(Query)    \n",
    "\n",
    "    for i in words_q:\n",
    "        Query_V[np.where(Vocabulary == i)] = 1\n",
    "\n",
    "    count = 0\n",
    "    for V in Doc_V:\n",
    "        doc_score_dic[count] = np.dot(Query_V, V)\n",
    "        count = count + 1\n",
    "    \n",
    "    return doc_score_dic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.918017338861666\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "                             Diabetes       1.00      0.89      0.94      1220\n",
      "               Cardiovascular Disease       1.00      0.87      0.93      2289\n",
      "Chronic Obstructive Pulmonary Disease       1.00      1.00      1.00      1797\n",
      "                               Cancer       0.00      0.00      0.00         0\n",
      "\n",
      "                             accuracy                           0.92      5306\n",
      "                            macro avg       0.75      0.69      0.72      5306\n",
      "                         weighted avg       1.00      0.92      0.96      5306\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "y_true = test['Topic'].tolist()\n",
    "\n",
    "y_pre = []\n",
    "for q in test['Question']:\n",
    "    d = tfidf_classify(q)\n",
    "    y_pre.append(classes[max(d, key=d.get)])\n",
    "    \n",
    "\n",
    "acc = accuracy_score(y_pre, y_true)\n",
    "print(\"Accuracy\", acc )\n",
    "print(classification_report(y_true, y_pre, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Similarity Method using WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Diabetes', 'Cardiovascular Disease', 'Chronic Obstructive Pulmonary Disease', 'Cancer']\n",
    "\n",
    "docList = []\n",
    "for cls in classes:\n",
    "    #reading the documents one by one\n",
    "    text = open(cls+\".txt\", \"r\").read()\n",
    "    \n",
    "    #preprocessing the text in each of the files\n",
    "    docList.append(preprocessing(text))    \n",
    "\n",
    "#removing all the duplicate tokens from the data\n",
    "for i in range(len(docList)):\n",
    "    docList[i] = list(set(docList[i]))\n",
    "    \n",
    "enhDocList = []\n",
    "for doc in docList:\n",
    "    enhDocList.append(list(set(doc + [w for word in doc for w in get_synonyms(word)])))\n",
    "\n",
    "    \n",
    "    \n",
    "def wordSim_classify(Query):\n",
    "\n",
    "    queryList = list(set(preprocessing(Query)))\n",
    "    enhQuery = queryList + list(set([w for word in queryList for w in get_synonyms(word)]))\n",
    "\n",
    "    similarity = [0, 0, 0, 0]\n",
    "    for word in queryList:\n",
    "        for i in range(len(docList)):\n",
    "            for w in docList[i]:\n",
    "                similarity[i] = similarity[i] + count_simlilarity(word, w)\n",
    "    similarity = [n/len(queryList) for n in similarity]\n",
    "\n",
    "    match_count= [0, 0, 0, 0]\n",
    "    for word in enhQuery:\n",
    "        for i in range(len(docList)):\n",
    "            for w in docList[i]:\n",
    "                if(word==w):\n",
    "                    match_count[i] = match_count[i] + 1\n",
    "    similarity = [x + y for x, y in zip(similarity, match_count)]\n",
    "    \n",
    "    doc_score_dic = {}\n",
    "    for i in range(len(similarity)):\n",
    "        doc_score_dic[i] = similarity[i]\n",
    "        \n",
    "    return doc_score_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9858650584244252\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "                             Diabetes       1.00      1.00      1.00      1220\n",
      "               Cardiovascular Disease       1.00      0.97      0.98      2289\n",
      "Chronic Obstructive Pulmonary Disease       1.00      1.00      1.00      1797\n",
      "                               Cancer       0.00      0.00      0.00         0\n",
      "\n",
      "                             accuracy                           0.99      5306\n",
      "                            macro avg       0.75      0.74      0.75      5306\n",
      "                         weighted avg       1.00      0.99      0.99      5306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "y_true = test['Topic'].tolist()\n",
    "\n",
    "y_pre = []\n",
    "for q in test['Question']:\n",
    "    d = wordSim_classify(q)\n",
    "    y_pre.append(classes[max(d, key=d.get)])\n",
    "    \n",
    "\n",
    "acc = accuracy_score(y_pre, y_true)\n",
    "print(\"Accuracy\", acc )\n",
    "print(classification_report(y_true, y_pre, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cardiovascular Disease'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Query = \"high blood pressure and heart pain\"\n",
    "d = wordSim_classify(Query)\n",
    "\n",
    "classes[max(d, key=d.get)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 10.786472102029375,\n",
       " 1: 11.159881576971358,\n",
       " 2: 2.5339977016447612,\n",
       " 3: 6.0582517668090405}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
